

 
 
# Resultados


Uno de los objetivos fundamentales del presente trabajo es poner a prueba distintos métodos y algoritmos de pronóstico de series temperales para predecir el flujo de tráfico con los datos reportados por los dispositivos de medida de la ciudad de Madrid.

Como hemos visto en los capítulos anteriores, se han utilizado métodos paramétricos, basados en el modelado de series temporales  descomponiéndolas en componentes de tendencia y estacionalidad, métodos basados en autoregresión y media móviles, y métodos basados en aprendizaje profundo (deep learning).

Concretamente, se han puesto a prueba los métodos que pueden verse en la siguiente lista. Para cada uno podemos ver una pequeña descripción de su implementación. Para los detalles exactos del método, se recomienda acudir al repositorio [@amanas-github]. Podemos ver que cada experimento viene etiquetado con la familia de métodos a la que pertenece. Esto nos permitirá más adelante seleccionar el mejor de cada familia y expresar los resultados de una forma más clara o resumida atendiendo sólo al método que mejor rinde por familia. Los métodos son:


<!-- # ```{r exps-fam-name-desc-tab, include=F} -->
<!-- # tff.release.pool() -->
<!-- # tff.metodos %>% select(Familia, Nombre, Descripcion) %>% arrange(Familia, Nombre) %>% -->
<!-- #     tff.kable.default(caption = "Métodos probados en el presente estudio: familia, nombre y descripción") -->
<!-- # ``` -->


* Familia ARIMA:
    * **AUTO ARIMA**. Método ARIMA ajustado automáticamente en cada serie.
    * **SARIMA**. Método ARIMA estacional.

* Familia LSTM:
    * **LSTM Agg4 Diff**. LSTM entrenado con los datos de las 8 semanas más recientes, transformando la serie a granularidad de una hora y  diferenciando.
    * **LSTM Agg4 Diff Scale Mean**.	LSTM entrenado con los datos de las 8 semanas más recientes, transformando la serie a granularidad de  una hora, diferenciando y escalando con centro y escala la media.
    * **LSTM Agg4 Scale Mean**. LSTM entrenado con los datos de las 8 semanas más recientes, transformando la serie a granularidad de una  hora y escalando con centro y escala la media.
    * **LSTM	LSTM Agg4 Scale SD**. LSTM entrenado con los datos de las 8 semanas más recientes, transformando la serie a granularidad de una hora y  escalando con centro la media y escala la desviación típica de la serie.

* Familia LSTM Exógeno:	
    * **LSTM-Exo DH Agg5 Scale Mean**. LSTM entrenado con los datos de las 8 semanas más recientes, incorporando la hora del día y el día de la semana como variables exógenas, transformando la serie a granularidad de 75 minutos y escalando con centro y escala la media.
    * **LSTM-Exo DH Raw Scale Mean**. LSTM entrenado con los datos de las 8 semanas más recientes, incorporando la hora del día y el día de la semana como variables exógenas y escalando con centro y escala la media.

* Familia MIXTO STL LSTM:	
    * **STL+LSTM Agg5 Scale Mean**. Ajuste STL a 6 meses de datos más recientes de la serie considerando estacionalidad semanal. Porteriormente, los residuos de STL se modelan con LSTM transformando la serie a granularidad de 75 minutos.
    * **STL+LSTM Raw Scale Mean**. Ajuste STL a 6 meses de datos más recientes de la serie considerando estacionalidad  semanal. Porteriormente, los residuos de STL se modelan con LSTM transformando la serie a granularidad de 1 hora y escalando con centro y escala la media.

* Familia STL:	
    * **STL D**. STL con estacionalidad diaria ajustado en toda la serie.
    * **STL D Reciente**. STL con estacionalidad diaria ajustado en los 6 meses de datos previos al punto de pronóstico.
    * **STL M**. STL con estacionalidad mensual ajustado en toda la serie.
    * **STL M Reciente**. STL con estacionalidad mensual ajustado en los 6 meses de datos previos al punto de pronóstico.
    * **STL W**. STL con estacionalidad semanal ajustado en toda la serie.
    * **STL W Reciente**. STL con estacionalidad semanal ajustado en los 6 meses de datos previos al punto de pronóstico.
    * **STL Y**. STL con estacionalidad anual ajustado en toda la serie.

* Familia STLM:
    * **STLM DW**. STLM con estacionalidades diaria y semanal ajustado en toda la serie.
    * **STLM DWM**. STLM con estacionalidades diaria, semanal y mensual ajustado en toda la serie.
    * **STLM DWM Reciente**. STLM con estacionalidades diaria, semanal y mensual ajustado en los 6 meses de datos previos al punto de  pronóstico.
    * **STLM DWY**.	STLM con estacionalidades diaria, semanal y anual ajustado en toda la serie.





La forma de realizar el experimento de contraste ha sido aplicar los distintos algortimos puestos a prueba a todas las series de tiempo y comparar los resultados pronosticados por cada algoritmo contra la serie conocida real. En número de dispositivos de los que se tienen datos suficientes como para practicar estos experimentos es 3.976. Esto nos permite confiar en que los promedios de error de cada algoritmo realmente serán significativos de su capacidad de modelado y pronóstico. 

Igualmente, el punto de prueba para cada serie se ha elegido aleatoriamente en el intervalo de los últimos 12 meses de datos de la serie, lo que nos libera de posibles sesgos que se puedieran producir por seleccionar siempre puntos en un mismo día del año o de la semana o a una misma hora del día. Recordemos, que como explicábamos más arriba, todos los métodos aplicados a una serie se han aplicado sobre el mismo instante aleatorio en los 12 meses más recientes. Pero este instante no tiene por qué ser el mismo (y no lo es) para todas las series.

Cada algoritmo de los probados ofrece pronósticos a 48 horas vista con una granularidad de 15 minutos. Esto nos permite someterlos a contraste según diferentes horizontes de pronóstico. En el Cuadro \@ref(tab:exps-by-method-tab) podemos ver el número de experimentos válidos realizados por cada método de los que citábamos en la lista de anterior.


\begin{longtable}{llr}
\caption{(\#tab:exps-by-method-tab)Número de experimentos realizados por cada método}\\
\toprule
Familia & Nombre & Experimentos realizados\\
\midrule
\endfirsthead
\caption[]{(\#tab:exps-by-method-tab)Número de experimentos realizados por cada método \textit{(continued)}}\\
\toprule
Familia & Nombre & Experimentos realizados\\
\midrule
\endhead
\
\endfoot
\bottomrule
\endlastfoot
\rowcolor{gray!6}  ARIMA & AUTO ARIMA & 3975\\
ARIMA & SARIMA & 3970\\
\rowcolor{gray!6}  LSTM & LSTM Agg4 Diff & 3719\\
LSTM & LSTM Agg4 Diff Scale Mean & 3724\\
\rowcolor{gray!6}  LSTM & LSTM Agg4 Scale Mean & 3727\\
\addlinespace
LSTM & LSTM Agg4 Scale SD & 3725\\
\rowcolor{gray!6}  LSTM Exógeno & LSTM-Exo DH Agg5 Scale Mean & 3972\\
LSTM Exógeno & LSTM-Exo DH Raw Scale Mean & 3972\\
\rowcolor{gray!6}  MIXTO STL LSTM & STL+LSTM Agg5 Scale Mean & 2502\\
MIXTO STL LSTM & STL+LSTM Raw Scale Mean & 2508\\
\addlinespace
\rowcolor{gray!6}  STL & STL D & 3975\\
STL & STL D Reciente & 3975\\
\rowcolor{gray!6}  STL & STL M & 3973\\
STL & STL M Reciente & 3974\\
\rowcolor{gray!6}  STL & STL W & 3975\\
\addlinespace
STL & STL W Reciente & 3976\\
\rowcolor{gray!6}  STL & STL Y & 3704\\
STLM & STLM DW & 3976\\
\rowcolor{gray!6}  STLM & STLM DWM & 3976\\
STLM & STLM DWM Reciente & 3976\\
\addlinespace
\rowcolor{gray!6}  STLM & STLM DWY & 3976\\*
\end{longtable}



**En los próximos apartados, siempre que hablemos del error cometido por cualquier método para un horizonte $h$, nos referimos al agregado de errores cometidos entre en el intervalo de predicciones que van desde el primer valor pronosticado hasta el $h$-ésimo valor pronosticado.** Es importante tener esto muy presente para la interpretación de los resultados que veremos a continuación.


## Métricas de error


Un mismo pronóstico puede compararse con el valor real esperado atendiendo a diferentes medidadas de error. 

Un "error" de pronóstico es la diferencia entre un valor observado y su pronóstico. Es decir, "error" no significa un mal funcionamiento, significa la parte impredecible de una observación. Se puede escribir como:

$$e_T = y_T - \hat{y}_T$$ 

dónde $\{ y_1, \dots, y_t \}, t \in T$, se refieren a los datos observados y $\{ \hat{y}_1, \dots, \hat{y}_t \}, t \in T$, son los datos pronosticados.


A priori, no tiene por qué haber una medida del error que sea mejor que otra; para cada caso, dependiendo de la naturaleza del fenómeno que se pronostica, puede convenir utilizar unas u otras métricas, teniendo siempre claro como interpretar la información arrojada por cada una. 

Sin embargo, si conviene aclarar la diferencia que hay entre métricas dependientes de la escala y métricas agnósticas de escala. Acudimos nuevamente a [@Forecast6-online].

**Las medidas de error dependientes de la escala** son aquellas en las que las mediciones de los errores de pronóstico están en la misma escala que los datos que se pronostican. El principal inconveniente de este tipo de medidad es que no se pueden usar para hacer comparaciones entre series que involucran diferentes unidades o series que utilizando la misma unidad tienen unos datos muy diferentes. Por ejemplo, si en una vía la media de carga es del 50% con una varianza del 50% y en otra es sólo del 2% con una varianza del 5%, si un método de pronóstico tuviera un error $\epsilon$ en ambas series, parece que podríamos pensar que el método modela mejor la vía con mayor carga puesto que la magnitud y variabilidad de los datos es mayor.

Las dos medidas dependientes de la escala más utilizadas se basan en los errores absolutos (MAE) o los errores cuadrados (RMSE). Cuando se comparan los métodos de pronóstico aplicados a una sola serie de tiempo, o a varias series de tiempo con las mismas unidades, el MAE es popular porque es fácil de entender y calcular. Un método de pronóstico que minimiza el MAE conduce a pronósticos de la mediana, mientras que minimizar el RMSE conduce a pronósticos de la media. En consecuencia, el RMSE también se usa ampliamente, a pesar de ser más difícil de interpretar. Más adelante veremos como se definen formalmente.

**Las medidas de error agnósticas de escala** típicamente se expresan como porcentajes. Los errores de porcentaje tienen la ventaja de estar libres de unidades, por lo que se usan con frecuencia para comparar los rendimientos de pronóstico entre diferentes conjuntos de datos. En el caso de nuestran investigación, esto es bastante importante al ser bastante heterogéneo la distribución que adopta la carga según el dispositivo (véanse las observaciones hechas más arriba sobre medidas dependientes de la escala).

El porcentaje de error típicamente viene dado por:

$$p_t = 100 \frac{e_t}{y_t}, t \in T$$
  
siendo $e_t$ el error cometido en el pronóstico en el instante $t$, $y_{t}$ el valor real conocido.

La medida más utilizada es el MAPE, que definimos más adelante.


Las medidas basadas en errores de porcentaje tienen la desventaja de ser infinitas o indefinidas si $y_{t}=0$ para algún $t$ en el período de interés, y tener valores extremos si algún  $y_{t}$ está próximo a 0.

También tienen la desventaja de que imponen una mayor penalización a los errores negativos que a los positivos. Esta observación condujo al uso del llamado MAPE "simétrico" (sMAPE) propuesto por [@armstrong1985long], que no obstante, no utilizamos en nuestro reporte.


Hechas las aclaraciones anteriores, que nos permitirán interpretar mejor los resultados, describimos ahora cada una de las métricas utilizadas [@hyndman2006another]:

* **ME (error medio)** es la media de los errores cometidos en el conjunto de pronósticos. 

$$ ME = mean(e_t), t\in T $$


* **MAE (error absoluto medio)** es la media de los errores absolutos cometidos en el conjunto de pronósticos. 

$$ MAE = mean(|e_t|), t\in T $$

* **RMSE (raiz del error cuadrático medio)** es la raiz cuadrada de la media de los errores cuadráticos cometidos en el conjunto de pronósticos. 

$$ RMSE = \sqrt{\text{mean}(e_t^2)}, t\in T $$

* **MPE (error porcentual medio)** es la media de los errores porcentuales cometidos en el conjunto de pronósticos.

$$ MPE = mean(p_t), t\in T $$

* **MAPE (error porcentual absoluto medio)** es la media de los errores porcentuales absolutos cometidos en el conjunto de pronósticos. 

$$ MAPE = mean(|p_t|), t\in T $$


