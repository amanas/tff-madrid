




## LSTM univariado
 

Las redes neuronales recurrentes, RNN, son un tipo de redes capaces de reconocer y predecir secuencias de datos a lo largo del tiempo, como textos, genomas, discurso hablado o series numéricas. Este tipo de redes se fundamentan en bucles que permiten que la salida de la red o de una parte de ella en un momento dado sirva como entrada de la propia red en el siguiente momento.

Para entender el funcionamiento de las RNNs, podemos considerar un perceptrón multicapa con una sóla capa oculta de manera que la salida del perceptrón es utilizada como entrada en la siguiente evaluación. Este bucle en la arquitectura de la red es precisamente lo que permite a la red "recordar" información a lo largo del tiempo. En la medida en la que le añadimos capas, su capacidad de modelado irá creciendo de manera que será capaz de reconocer mayores secuencias cada vez con menor error. 


\begin{figure}[H]

{\centering \includegraphics[width=0.1\linewidth]{images/RNN_basic} 

}

\caption{Arquitectura RNN básica}(\#fig:RNN-basic)
\end{figure}

Véase la Figura \@ref(fig:RNN-basic), dónde:

- $\text{A}$ es una red neuronal
- $X_t$ es la entrada de la red
- $h_t$ es la salida de la red

Precisamente es el bucle que conecta la red consigo misma el mecanismo que permite que la red tenga memoria.

Las RNNs pueden verse también como múltiples copias de la misma red, cada una de ellas pasando información a su sucesora. Véase la Figura \@ref(fig:RNN-unrolled). En cada momento del tiempo $t$, la red recibe como entrada tanto $X_t$ como su propia salida $h_{t-1}$ en el instante $t-1$.


\begin{figure}[H]

{\centering \includegraphics[width=0.6\linewidth]{images/RNN_unrolled} 

}

\caption{Arquitectura RNN expandida}(\#fig:RNN-unrolled)
\end{figure}


Las RNNs tienen un contratiempo importante conocido como **problema del desvanecimiento del gradiente**; es decir, tienen dificultades para aprender dependencias de largo alcance. Cuando se realiza la propagación hacia atrás, es decir, nos movemos hacia atrás en la red y calculamos los gradientes de pérdida (error) con respecto a los pesos, los gradientes tienden a ser cada vez más pequeños a medida que nos movemos hacia atrás en la red. Esto significa que las neuronas en las capas anteriores aprenden muy lentamente en comparación con las neuronas en las capas posteriores en la jerarquía. Las capas anteriores de la red son las más lentas de entrenar. Este es un problema en todos los tipos de redes neuronales, pero particularmente es nocivo para redes en dónde lo que se pretende es tener la componente de memoria necesaria para pronóstico de series temporales.

Afortunadamente, este problema fue resuelto por [@hochreiter1997long] mediante la creación de las **LSTM**. Las redes de memoria a corto/largo plazo, LSTM, son un tipo especial de RNN, capaz de aprender dependencias a largo plazo.

Las LSTM están diseñados explícitamente para evitar el problema de dependencia a largo plazo. Recordar información durante largos períodos de tiempo es prácticamente su comportamiento predeterminado. Todas las redes neuronales recurrentes tienen la forma de una cadena de módulos repetitivos de la red neuronal. En las RNN estándar, este módulo de repetición tendrá una estructura muy simple, como una sola capa de activación. Los LSTM también tienen esta estructura tipo cadena, pero el módulo de repetición tiene una estructura diferente. En lugar de tener una sola capa de red neuronal, hay cuatro que interactúan de una manera muy especial (Figura \@ref(fig:LSTM-chain)).



\begin{figure}[H]

{\centering \includegraphics[width=0.6\linewidth]{images/LSTM3-chain} 

}

\caption{Capas de las celdas LSTM}(\#fig:LSTM-chain)
\end{figure}

La clave de las redes LSTM es el estado de la célula, la línea horizontal que recorre la parte superior del diagrama. El estado de la célula es algo así como una cinta transportadora. Corre hacia abajo por toda la cadena, con solo algunas interacciones lineales menores. Es muy fácil que la información fluya sin cambios. El LSTM tiene la capacidad de eliminar o agregar información al estado de la célula, cuidadosamente regulado por estructuras llamadas compuertas.

Las puertas son una forma de permitir que la información fluya. Se componen de una capa de red neuronal sigmoidea y una operación de multiplicación puntual. La capa sigmoide produce números entre cero y uno, que describen la cantidad de cada componente que debe dejarse pasar. Un valor de cero significa "no dejar pasar nada", mientras que un valor de uno significa "dejar pasar todo". Un LSTM tiene tres de estas compuertas, para proteger y controlar el estado de la celda.

Para ampliar conocimientos sobre el funcionamiento de las redes LSTM se recomienda revisar el fantástico artículo [@olah2015lstm].

Afortunadamente, para utilizar este tipo de red no es necesario implementarlas desde cero, sino que se pueden utilizar distintos frameworks. Como se explicará más adelante, los experimentos que hemos realizado se han basado en Keras sobre TensorFlow.




### Descripción del experimento

Las LSTMs son sensibles a la escala de los datos de entrada, especialmente cuando se utilizan las funciones de activación sigmoide (por defecto) o tanh. Para evitar este problema, hemos reescalado los datos al rango de 0 a 1. 


La siguiente parte se relaciona con la estructura como se le presentan las series a la red para que proceda al aprendizaje. Las redes LSTM, al menos en la implementación de Keras, esperan una entrada del tipo *[muestras, pasos de tiempo, características]*. Para esto, dada una serie de carga, se ha elegido un tamaño de sub-serie de entrenamiento (*look back*) y un tamaño de sub-serie de pronóstico (*look ahead*).

Sin embargo, es importante resaltar que en el caso de este algoritmo no se han obtenido buenos resultados considerando la serie en crudo (con los outlayers propios que pueda tener). Se ha comprobado que el algoritmo converge mejor y da mejores resultados si la serie se suaviza a granularidad de 1 hora.

En el contexto del suavizado indicado anteriormente, el valor *look ahead* utilizado es $92/4 = 48$. Recordemos que el objetivo de esta investigación son pronósticos a 48 horas vista (96 valores con granularidad de 15 minutos, es decir, 48 con granularidad de una hora).

Respecto a la estrategia de pronóstico seguida, se ha utilizado la múltiple. Se han realizado bastantes pruebas siguiendo la estrategia recursiva no habiéndose llegado a resultados satisfactorios.

Tras muchas pruebas en las que se ha contrastado tanto los resultados arrojados por el algoritmo como los recursos y tiempo necesarios para el entrenamiento, se ha observado que un valor de *look back* que ofrece un buen rendimiento es tomar el mismo que se utiliza para *look ahead* (48 valores).

Por otro lado, hay dos formas de definir las redes LSTM en keras: redes con estado (statefull) o redes sin estado (stateless) entre muestras dentro del mismo lote de entrenamiento. Cuando se definen redes que con estado, esto significa que las muestras que componen los diferentes lotes de cada época de entrenamiento deben ser consecutivas en su índice dentro del lote. 

En este trabajo se han probado ambos enfoques no llegándose a conseguir que las redes que no se definen con estado converjan.

Para las redes que se definen con estado, efectivamente sí se han conseguido que converjan y los pronósticos, como veremos más adelante, son relativamente satisfactorios. La parte que tiene que ver con diseccionar una serie de carga en distintos lotes, garantizando que los lotes satisfagan las indicaciones dadas más arriba ha sido realmente trabajosa, pero finalmente los resultados han sido redes LSTM's capaces de pronosticar el flujo.

Se ha prestado especial atención a que las redes no acaben sobre-entrenadas. Esto se gestiona con bastante ergonomía en keras, disponiendo de *callbacks* que paran el entrenamiento cuando la mejora en la disminución de errores no es significativa tras una o más épocas.

En el capítulo de resultados veremos cómo se comportan estos algoritmos en comparación con los métodos paramétricos que hemos explorado en los apartados anteriores. Pero por ahora, por ejemplo, para el terminal 5575, en la Figura \@ref(fig:LSTM-5575), podemos ver los pronósticos hechos con LSTM. Obsérvese como los pronósticos con LSTM están bastante suavizados, en coherencia con los comentarios sobre suavizado de datos hechos más arriba.


\begin{figure}[H]

{\centering \includegraphics[width=0.6\linewidth]{422.metodo.deep.lstm.univariado_files/figure-latex/LSTM-5575-1} 

}

\caption{Pronóstico del flujo de carga para el terminal 5.575 con LSTM}(\#fig:LSTM-5575)
\end{figure}



<!-- ## LSTM multivariado -->


## LSTM con variables exógenas

En las series del flujo de tráfico existe una componente de comportamiento humano que no debe ser despreciada. En particular, los humanos ajustamos nuestros hábitos según las horas del día y los días de la semana. Esta información viene reportada en los datos que hemos trabajado, pero hasta ahora, en ninguno de los modelos anteriores hemos considerado esta información como una variable de entrada.

Es de esperar que ayudando al modelo ofreciéndole como entrada esta nueva fuente de información ofrezca un rendimiento mejor. En particular, esto puede ser de especial utilidad en los modelos basados en aprendizaje profundo, independientemente de que hay técnicas que permiten seguir este enfoque también con los modelos paramétricos.

Esta técnica se ha seguido para algunos modelos basados en LSTM. Concretamente, los modelos **LSTM-Exo DH Raw Scale Mean** y **LSTM-Exo DH Agg5 Scale Mean** han sido construidos de este modo. 

Para ambos modelos, se han utilizado además de los datos de carga de la serie, dos nuevas **variables exógenas**, *la hora del día* y *el día de la semana*. En lugar de construir modelos complejos, con varias vías de entrada, se han encapsulado estas variables junto con la carga en una única variable formada por 3 componentes. Como suele ser habitual en el caso de redes neuronales, los datos han sido escalados al intervalo [-1,1].

En ambos casos, los resultados han mejorado bastante, como veremos en detalle en el capítulo de resultados.
